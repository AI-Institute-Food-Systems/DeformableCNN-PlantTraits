{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/plant-ai-biophysics-lab/DeformableCNN-PlantTraits/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/plant-ai-biophysics-lab/DeformableCNN-PlantTraits.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/DeformableCNN-PlantTraits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install albumentations==1.1.0\n",
    "!pip install agml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and config setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.functional import split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datatools import *\n",
    "from engine import train_single_epoch, validate\n",
    "from loss import NMSELoss\n",
    "from architecture import GreenhouseMidFusionRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download 2021 Autonomous Greenhouse Challenge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agml\n",
    "loader = agml.data.AgMLDataLoader('autonomous_greenhouse_regression', dataset_path = './')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data and output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sav_dir='model_weights/'\n",
    "if not os.path.exists(sav_dir):\n",
    "    os.mkdir(sav_dir)\n",
    "RGB_Data_Dir   = './autonomous_greenhouse_regression/images/'\n",
    "Depth_Data_Dir = './autonomous_greenhouse_regression/depth_images/'  \n",
    "JSON_Files_Dir = './autonomous_greenhouse_regression/annotations.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop the data if necessary (if you did this beforehand on ImageJ or you don't need to crop don't run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "min_x=650\n",
    "max_x=1450\n",
    "min_y=200\n",
    "max_y=900\n",
    "cropped_img_dir='./autonomous_greenhouse_regression/cropped_images/'\n",
    "\n",
    "cropped_depth_img_dir='./autonomous_greenhouse_regression/cropped_depth_images/'\n",
    "\n",
    "if not os.path.exists(cropped_img_dir):\n",
    "    os.mkdir(cropped_img_dir)\n",
    "\n",
    "if not os.path.exists(cropped_depth_img_dir):\n",
    "    os.mkdir(cropped_depth_img_dir)\n",
    "\n",
    "for im, depth_im in zip(os.listdir(RGB_Data_Dir), os.listdir(Depth_Data_Dir)):\n",
    "    img = plt.imread(RGB_Data_Dir+im)\n",
    "    crop_img = img[min_y:max_y,min_x:max_x]\n",
    "    plt.imsave(cropped_img_dir+im, crop_img)\n",
    "\n",
    "    depth_img = plt.imread(Depth_Data_Dir+depth_im)\n",
    "    crop_depth_img = depth_img[min_y:max_y,min_x:max_x]\n",
    "    plt.imsave(cropped_depth_img_dir+depth_im, crop_depth_img)\n",
    "\n",
    "RGB_Data_Dir   = cropped_img_dir\n",
    "Depth_Data_Dir = cropped_depth_img_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set model architectures options:\n",
    "- single vs. multi input (SI- or MI-)\n",
    "- single vs. multi output (-SO or -MO)\n",
    "- deformable vs. standard convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvType = 'deformable' # 'standard'\n",
    "\n",
    "training_category = 'MIMO' #'MIMO', 'MISO', 'SIMO', 'SISO'\n",
    "\n",
    "# Multi-input, multi-output model\n",
    "if training_category   == 'MIMO':\n",
    "    # transform_type = get_transforms(train=False) \n",
    "    inputs = ['RGB-D']\n",
    "    outputs = ['ALL']\n",
    "    NumOutputs = 5\n",
    "    \n",
    "# Multi-input, single-output model\n",
    "elif training_category == 'MISO':\n",
    "    # transform_type = get_transforms(train=False, (0,0,0,0), (1,1,1,1))\n",
    "    inputs = ['RGB-D']\n",
    "    outputs = ['FreshWeightShoot','FreshWeightShoot','Height','Diameter','LeafArea']\n",
    "    NumOutputs = 1\n",
    "    \n",
    "# Single-input, multi-output model\n",
    "elif training_category == 'SIMO':\n",
    "    # transform_type = get_RGB_transforms(train=False)\n",
    "    inputs = ['RGB','D']\n",
    "    outputs = ['ALL']\n",
    "    NumOutputs = 5\n",
    "    \n",
    "# Single-input, single-output model\n",
    "elif training_category == 'SISO':\n",
    "    # transform_type = get_RGB_transforms(train=False)\n",
    "    inputs = ['RGB','D']\n",
    "    outputs = ['FreshWeightShoot','FreshWeightShoot','Height','Diameter','LeafArea']\n",
    "    NumOutputs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set other model config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seed = 12    \n",
    "num_epochs = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create PyTorch dataset, create PyTorch dataloader, and split train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the PyTorch datalaoder the autonomous greenhouse dataset.\n",
    "dataset = GreenhouseDataset(rgb_dir = RGB_Data_Dir, \n",
    "                            d_dir = Depth_Data_Dir, \n",
    "                            jsonfile_dir = JSON_Files_Dir, \n",
    "                            transforms = get_transforms(train=False, means=[0,0,0,0],stds=[1,1,1,1] )) \n",
    "\n",
    "# Remove last 50 images from training/validation set. These are the test set.                         \n",
    "dataset.df= dataset.df.iloc[:-50]\n",
    "\n",
    "# Split train and validation set. Stratify based on variety.\n",
    "train_split, val_split = train_test_split(dataset.df, \n",
    "                                          test_size = 0.2, \n",
    "                                          random_state = split_seed,\n",
    "                                          stratify = dataset.df['outputs'].str['classification']) #change to None if you don't have class info\n",
    "train = torch.utils.data.Subset(dataset, train_split.index.tolist())\n",
    "val   = torch.utils.data.Subset(dataset, val_split.index.tolist())\n",
    "                                                                                     \n",
    "# Create train and validation dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=6, num_workers=6, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(val,   batch_size=6, shuffle=False, num_workers=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the mean and standard deviation of images for normalization (Only need to do once for a new dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.4843, 0.4585, 0.4053, 0.0150])\n",
      "Standard Deviation tensor([0.1367, 0.1400, 0.1932, 0.0068])\n"
     ]
    }
   ],
   "source": [
    "# this part is just to check the MEAN and STD of the dataset (dont run unless you need mu and sigma)\n",
    "\n",
    "\n",
    "nimages = 0\n",
    "mean = 0.\n",
    "std = 0.\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=False, num_workers=12)\n",
    "dataset.input = 'RGB-D'\n",
    "dataset.out = 'ALL'\n",
    "for batch, _ in dataloader:\n",
    "\n",
    "    # Rearrange batch to be the shape of [B, C, W * H]\n",
    "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "    # Update total number of images\n",
    "    nimages += batch.size(0)\n",
    "    # Compute mean and std here\n",
    "    mean += batch.mean(2).sum(0) \n",
    "    std += batch.std(2).sum(0)\n",
    "\n",
    "# Final step\n",
    "mean /= nimages\n",
    "std /= nimages\n",
    "\n",
    "print('Mean: '+ str(mean))\n",
    "print('Standard Deviation', str(std))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function as Normalized Mean Squared Error, as required for the 2021 Autonomous Greenhouse Challenge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NMSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training loop and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "device = torch.device('cuda')\n",
    "\n",
    "for input in inputs:\n",
    "    for output in outputs:\n",
    "        dataset.input = input\n",
    "        dataset.out = output\n",
    "        model = GreenhouseMidFusionRegressor(input_data_type = input, num_outputs = NumOutputs, conv_type = ConvType)\n",
    "        model.to(device)\n",
    "        params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "        optimizer = torch.optim.Adam(params, \n",
    "                                     lr=0.0005, \n",
    "                                     betas=(0.9, 0.999), \n",
    "                                     eps=1e-08, \n",
    "                                     weight_decay = 0, \n",
    "                                     amsgrad = False)  # select an optimzer for each run\n",
    "    \n",
    "                                \n",
    "        best_val_loss = 9999999 # initial dummy value\n",
    "        current_val_loss = 0\n",
    "        # training_val_loss=0\n",
    "           \n",
    "        writer = SummaryWriter()\n",
    "        start = time.time()\n",
    "                                \n",
    "        for epoch in range(num_epochs):\n",
    "            with open('run.txt', 'a') as f:\n",
    "                f.write('\\n')\n",
    "                f.write('Epoch: '+ str(epoch + 1) + ', Time Elapsed: '+ str((time.time()-start)/60) + ' mins')\n",
    "            print('Epoch: ', str(epoch + 1), ', Time Elapsed: ', str((time.time()-start)/60), ' mins')\n",
    "\n",
    "            train_single_epoch(model, dataset, device, criterion, optimizer, writer, epoch, train_loader)\n",
    "\n",
    "            best_val_loss = validate(model, dataset, device, training_category, sav_dir, criterion, writer, epoch, val_loader, best_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the PyTorch datalaoder the autonomous greenhouse dataset.\n",
    "testset = GreenhouseDataset(rgb_dir = RGB_Data_Dir, \n",
    "                            d_dir = Depth_Data_Dir, \n",
    "                            jsonfile_dir = JSON_Files_Dir, \n",
    "                            transforms = transform_type)\n",
    "\n",
    "# Grab last 50 images as test dataset\n",
    "testset.df = testset.df[-50:]\n",
    "\n",
    "# Get testset_size\n",
    "testset_size = testset.df.shape[0]\n",
    "\n",
    "# Create test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(testset, \n",
    "                                          batch_size = 50,\n",
    "                                          num_workers = 0, \n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss functions for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cri = NMSELoss()\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is  RGB-D\n",
      "FW MSE:  16857.876953125\n",
      "DW MSE:  4.854626655578613\n",
      "H MSE:  3.97654390335083\n",
      "D MSE:  22.738414764404297\n",
      "LA MSE:  5795591.0\n",
      "Overall NMSE:  1.632205843925476\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "device=torch.device('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input in inputs:\n",
    "        final = torch.zeros((testset_size,0))\n",
    "        all_targets = torch.zeros((testset_size,0))\n",
    "        for output in outputs:\n",
    "            print('Input is ', input)\n",
    "            testset.input = input\n",
    "            testset.out = output\n",
    "\n",
    "            device=torch.device('cuda')\n",
    "            model= GreenhouseMidFusionRegressor(input_data_type = input, \n",
    "                                                num_outputs = NumOutputs, \n",
    "                                                conv_type = ConvType)\n",
    "            model.to(device)\n",
    "            model.load_state_dict(torch.load(sav_dir + 'bestmodel' + training_category + '_' + input + '_' + output + '.pth'))\n",
    "            model.eval()\n",
    "\n",
    "\n",
    "            if output=='All':\n",
    "                ap=torch.zeros((0,5))\n",
    "                at=torch.zeros((0,5))\n",
    "            else:\n",
    "                ap=torch.zeros((0,1))\n",
    "                at=torch.zeros((0,1))\n",
    "\n",
    "            for rgbd, targets in test_loader:\n",
    "                rgbd = rgbd.to(device)\n",
    "                targets = targets.to(device)\n",
    "                preds = model(rgbd)\n",
    "                # mse_loss=mse(preds, targets)\n",
    "                # nmse=criterion(preds, targets)\n",
    "                # nmse, pred=cri(preds, targets)\n",
    "                ap=torch.cat((ap, preds.detach().cpu()), 0)\n",
    "                at=torch.cat((at, targets.detach().cpu()), 0)\n",
    "\n",
    "            if output=='All':\n",
    "                print('FW MSE: ', str(mse(ap[:,0],at[:,0]).tolist()))\n",
    "                print('DW MSE: ', str(mse(ap[:,1],at[:,1]).tolist()))\n",
    "                print('H MSE: ', str(mse(ap[:,2],at[:,2]).tolist()))\n",
    "                print('D MSE: ', str(mse(ap[:,3],at[:,3]).tolist()))\n",
    "                print('LA MSE: ', str(mse(ap[:,4],at[:,4]).tolist()))\n",
    "            else:\n",
    "                final=torch.cat((final, ap.detach().cpu()),1)\n",
    "                all_targets=torch.cat((all_targets, at.detach().cpu()),1)\n",
    "                print(output,' MSE: ', str(mse(ap,at).tolist()))\n",
    "\n",
    "        if output == 'All':\n",
    "            print('Overall NMSE: ', str(cri(ap,at).tolist()))\n",
    "        else:\n",
    "            print('Overall NMSE: ', str(cri(final,all_targets).tolist()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52f36c1f6eb8678621dd418d5b8ad0837811436cfff124e7936f8a687fb60368"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('greenhouse': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
