{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/plant-ai-biophysics-lab/DeformableCNN-PlantTraits/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/plant-ai-biophysics-lab/DeformableCNN-PlantTraits.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/DeformableCNN-PlantTraits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install albumentations==1.1.0\n",
    "!pip install agml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and config setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.functional import split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datatools import *\n",
    "from engine import train_single_epoch, validate\n",
    "from loss import NMSELoss\n",
    "from architecture import GreenhouseMidFusionRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download 2021 Autonomous Greenhouse Challenge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading autonomous_greenhouse_regression (size = 887.2 MB): 887226368it [00:33, 26634550.95it/s]                               ouse_regression.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AgML Download]: Extracting files for autonomous_greenhouse_regression... Done!\n",
      "\n",
      "================================================================================\n",
      "You have just downloaded \u001b[1mautonomous_greenhouse_regression\u001b[0m.\n",
      "\n",
      "This dataset is licensed under the \u001b[1mCC BY-SA 4.0\u001b[0m license.\n",
      "To learn more, visit: https://creativecommons.org/licenses/by-sa/4.0/\n",
      "\n",
      "When using this dataset, please cite the following:\n",
      "\n",
      "@misc{https://doi.org/10.4121/15023088.v1,\n",
      "  doi = {10.4121/15023088.V1},\n",
      "  url = {https://data.4tu.nl/articles/_/15023088/1},\n",
      "  author = {Hemming,  S. (Silke) and de Zwart,  H.F. (Feije) and Elings,  A. (Anne) and bijlaard,  monique and Marrewijk,  van,  Bart and Petropoulou,  Anna},\n",
      "  keywords = {Horticultural Crops,  Mechanical Engineering,  FOS: Mechanical engineering,  Artificial Intelligence and Image Processing,  FOS: Computer and information sciences,  Horticultural Production,  FOS: Agriculture,  forestry and fisheries,  Autonomous Greenhouse Challenge,  autonomous greenhouse,  Artificial Intelligence,  image processing,  computer vision,  Horticulture,  Lettuce,  sensors,  non-destructive sensing},\n",
      "  title = {3rd Autonomous Greenhouse Challenge: Online Challenge Lettuce Images},\n",
      "  publisher = {4TU.ResearchData},\n",
      "  year = {2021},\n",
      "  copyright = {Creative Commons Attribution 4.0 International}\n",
      "}\n",
      "\n",
      "You can find additional information about this dataset at:\n",
      "https://data.4tu.nl/articles/dataset/3rd_Autonomous_Greenhouse_Challenge_Online_Challenge_Lettuce_Images/15023088/1\n",
      "\n",
      "This message will \u001b[1mnot\u001b[0m be automatically shown\n",
      "again. To view this message again, in an AgMLDataLoader\n",
      "run `loader.info.citation_summary()`. Otherwise, you\n",
      "can use `agml.data.source(<name>).citation_summary().`\n",
      "\n",
      "You can find your dataset at /data/pvraja/DeformableCNN-PlantTraits/autonomous_greenhouse_regression.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import agml\n",
    "loader = agml.data.AgMLDataLoader('autonomous_greenhouse_regression', dataset_path = './')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data and output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sav_dir='model_weights/'\n",
    "if not os.path.exists(sav_dir):\n",
    "    os.mkdir(sav_dir)\n",
    "# RGB_Data_Dir   = './autonomous_greenhouse_regression/images/'\n",
    "# Depth_Data_Dir = './autonomous_greenhouse_regression/depth_images/'   \n",
    "\n",
    "\n",
    "RGB_Data_Dir='./autonomous_greenhouse_regression/cropped_images/'\n",
    "Depth_Data_Dir='./autonomous_greenhouse_regression/cropped_depth_images/'\n",
    "\n",
    "\n",
    "JSON_Files_Dir = './autonomous_greenhouse_regression/annotations.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop the data if necessary (if you did this beforehand or you don't need to crop don't run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "min_x=650\n",
    "max_x=1450\n",
    "min_y=200\n",
    "max_y=900\n",
    "cropped_img_dir='./autonomous_greenhouse_regression/cropped_images/'\n",
    "\n",
    "cropped_depth_img_dir='./autonomous_greenhouse_regression/cropped_depth_images/'\n",
    "\n",
    "if not os.path.exists(cropped_img_dir):\n",
    "    os.mkdir(cropped_img_dir)\n",
    "\n",
    "if not os.path.exists(cropped_depth_img_dir):\n",
    "    os.mkdir(cropped_depth_img_dir)\n",
    "\n",
    "for im in os.listdir(RGB_Data_Dir):\n",
    "    img = cv2.imread(RGB_Data_Dir+im)\n",
    "    crop_img = img[min_y:max_y,min_x:max_x]\n",
    "    cv2.imwrite(cropped_img_dir+im, crop_img)\n",
    "\n",
    "for depth_im in os.listdir(Depth_Data_Dir):\n",
    "    depth_img = cv2.imread(Depth_Data_Dir+depth_im, 0)\n",
    "    crop_depth_img = depth_img[min_y:max_y,min_x:max_x]\n",
    "    cv2.imwrite(cropped_depth_img_dir+depth_im, crop_depth_img)\n",
    "\n",
    "RGB_Data_Dir   = cropped_img_dir\n",
    "Depth_Data_Dir = cropped_depth_img_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set model architectures options:\n",
    "- single vs. multi input (SI- or MI-)\n",
    "- single vs. multi output (-SO or -MO)\n",
    "- deformable vs. standard convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvType = 'deformable' # 'standard'\n",
    "\n",
    "training_category = 'MIMO' #'MIMO', 'MISO', 'SIMO', 'SISO'\n",
    "\n",
    "# Multi-input, multi-output model\n",
    "if training_category   == 'MIMO':\n",
    "    # transform_type = get_transforms(train=False) \n",
    "    inputs = ['RGB-D']\n",
    "    outputs = ['ALL']\n",
    "    NumOutputs = 5\n",
    "    \n",
    "# Multi-input, single-output model\n",
    "elif training_category == 'MISO':\n",
    "    # transform_type = get_transforms(train=False, (0,0,0,0), (1,1,1,1))\n",
    "    inputs = ['RGB-D']\n",
    "    outputs = ['FreshWeightShoot','FreshWeightShoot','Height','Diameter','LeafArea']\n",
    "    NumOutputs = 1\n",
    "    \n",
    "# Single-input, multi-output model\n",
    "elif training_category == 'SIMO':\n",
    "    # transform_type = get_RGB_transforms(train=False)\n",
    "    inputs = ['RGB','D']\n",
    "    outputs = ['ALL']\n",
    "    NumOutputs = 5\n",
    "    \n",
    "# Single-input, single-output model\n",
    "elif training_category == 'SISO':\n",
    "    # transform_type = get_RGB_transforms(train=False)\n",
    "    inputs = ['RGB','D']\n",
    "    outputs = ['FreshWeightShoot','FreshWeightShoot','Height','Diameter','LeafArea']\n",
    "    NumOutputs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set other model config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seed = 12    \n",
    "num_epochs = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create PyTorch dataset, create PyTorch dataloader, and split train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the PyTorch datalaoder the autonomous greenhouse dataset.\n",
    "dataset = GreenhouseDataset(rgb_dir = RGB_Data_Dir, \n",
    "                            d_dir = Depth_Data_Dir, \n",
    "                            jsonfile_dir = JSON_Files_Dir, \n",
    "                            transforms = get_transforms(train=False, means=[0,0,0,0],stds=[1,1,1,1])) \n",
    "\n",
    "# Remove last 50 images from training/validation set. These are the test set.                         \n",
    "dataset.df= dataset.df.iloc[:-50]\n",
    "\n",
    "# Split train and validation set. Stratify based on variety.\n",
    "train_split, val_split = train_test_split(dataset.df, \n",
    "                                          test_size = 0.2, \n",
    "                                          random_state = split_seed,\n",
    "                                          stratify = dataset.df['outputs'].str['classification']) #change to None if you don't have class info\n",
    "train = torch.utils.data.Subset(dataset, train_split.index.tolist())\n",
    "val   = torch.utils.data.Subset(dataset, val_split.index.tolist())\n",
    "                                                                                     \n",
    "# Create train and validation dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=6, num_workers=6, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(val,   batch_size=6, shuffle=False, num_workers=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the mean and standard deviation of images for normalization (Only need to do once for a new dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.5482, 0.4620, 0.3602, 0.0127])\n",
      "Standard Deviation tensor([0.1639, 0.1761, 0.2659, 0.0035])\n"
     ]
    }
   ],
   "source": [
    "# this part is just to check the MEAN and STD of the dataset (dont run unless you need mu and sigma)\n",
    "\n",
    "nimages = 0\n",
    "mean = 0.\n",
    "std = 0.\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=False, num_workers=12)\n",
    "dataset.input = 'RGB-D'\n",
    "dataset.out = 'ALL'\n",
    "for batch, _ in dataloader:\n",
    "\n",
    "    # Rearrange batch to be the shape of [B, C, W * H]\n",
    "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "    # Update total number of images\n",
    "    nimages += batch.size(0)\n",
    "    # Compute mean and std here\n",
    "    mean += batch.mean(2).sum(0) \n",
    "    std += batch.std(2).sum(0)\n",
    "\n",
    "# Final step\n",
    "mean /= nimages\n",
    "std /= nimages\n",
    "\n",
    "print('Mean: '+ str(mean))\n",
    "print('Standard Deviation', str(std))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the output of the previous cells into here to avoid needing to redetermine mean and std every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.means=[0.5482, 0.4620, 0.3602, 0.0127]  #these values were copied from the previous cell\n",
    "dataset.stds=[0.1639, 0.1761, 0.2659, 0.0035]   #copy and paste the values to avoid having \n",
    "                                                # to rerun the previous cell for every iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function as Normalized Mean Squared Error, as required for the 2021 Autonomous Greenhouse Challenge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NMSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training loop and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , Time Elapsed:  2.1139780680338543e-06  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pvraja/miniconda3/envs/greenhouse/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train NMSE:  4.998493194580078\n",
      "Train NMSE:  4.72178316116333\n",
      "Train NMSE:  3.9732885360717773\n",
      "Train NMSE:  3.247258424758911\n",
      "Train NMSE:  3.2041726112365723\n",
      "Train NMSE:  2.9287607669830322\n",
      "Train NMSE:  2.434394598007202\n",
      "Train NMSE:  2.751041889190674\n",
      "Train NMSE:  2.396880865097046\n",
      "Train NMSE:  2.5686159133911133\n",
      "Train NMSE:  2.251461982727051\n",
      "Train NMSE:  2.2712419033050537\n",
      "Train NMSE:  2.08013653755188\n",
      "Train NMSE:  1.9583698511123657\n",
      "Train NMSE:  2.1400487422943115\n",
      "Train NMSE:  2.025778293609619\n",
      "Train NMSE:  2.335812568664551\n",
      "Train NMSE:  2.1013059616088867\n",
      "Train NMSE:  2.0247113704681396\n",
      "Train NMSE:  2.232846260070801\n",
      "Train NMSE:  1.9793753623962402\n",
      "Train NMSE:  1.8733950853347778\n",
      "Train NMSE:  2.0446555614471436\n",
      "Train NMSE:  1.9919730424880981\n",
      "Train NMSE:  1.8290690183639526\n",
      "Train NMSE:  2.040191411972046\n",
      "Train NMSE:  1.8791533708572388\n",
      "Train NMSE:  1.753008484840393\n",
      "Train NMSE:  1.9258697032928467\n",
      "Train NMSE:  1.8913615942001343\n",
      "Train NMSE:  1.8468819856643677\n",
      "Train NMSE:  1.9872393608093262\n",
      "Train NMSE:  1.8760783672332764\n",
      "Train NMSE:  1.8880976438522339\n",
      "Train NMSE:  4.688209533691406\n",
      "Train NMSE:  2.0485095977783203\n",
      "Train NMSE:  2.687164306640625\n",
      "Train NMSE:  2.4502127170562744\n",
      "Train NMSE:  3.3465499877929688\n",
      "Train NMSE:  2.840569496154785\n",
      "Train NMSE:  2.8380777835845947\n",
      "Train NMSE:  2.4850401878356934\n",
      "Train NMSE:  2.5605311393737793\n",
      "Train NMSE:  2.131208896636963\n",
      "Train NMSE:  1.7854639291763306\n",
      "Validating and Checkpointing!\n",
      "Best model Saved! Val NMSE:  137.5268075466156\n",
      "Epoch:  2 , Time Elapsed:  0.6742207328478496  mins\n",
      "Train NMSE:  1.778865933418274\n",
      "Train NMSE:  1.8056777715682983\n",
      "Train NMSE:  1.6219537258148193\n",
      "Train NMSE:  1.7191599607467651\n",
      "Train NMSE:  1.7037744522094727\n",
      "Train NMSE:  1.8907419443130493\n",
      "Train NMSE:  1.8824363946914673\n",
      "Train NMSE:  1.9223783016204834\n",
      "Train NMSE:  2.028367280960083\n",
      "Train NMSE:  2.121809959411621\n",
      "Train NMSE:  1.8791393041610718\n",
      "Train NMSE:  2.0087947845458984\n",
      "Train NMSE:  1.7317509651184082\n",
      "Train NMSE:  1.8998606204986572\n",
      "Train NMSE:  2.0838191509246826\n",
      "Train NMSE:  1.6215006113052368\n",
      "Train NMSE:  1.676023244857788\n",
      "Train NMSE:  1.7479543685913086\n",
      "Train NMSE:  1.6780741214752197\n",
      "Train NMSE:  1.691222071647644\n",
      "Train NMSE:  1.7100133895874023\n",
      "Train NMSE:  1.519239902496338\n",
      "Train NMSE:  1.7066352367401123\n",
      "Train NMSE:  1.4961692094802856\n",
      "Train NMSE:  4.372908115386963\n",
      "Train NMSE:  1.6292369365692139\n",
      "Train NMSE:  2.049407482147217\n",
      "Train NMSE:  2.4266586303710938\n",
      "Train NMSE:  2.582926034927368\n",
      "Train NMSE:  2.735860586166382\n",
      "Train NMSE:  2.8952996730804443\n",
      "Train NMSE:  3.114219903945923\n",
      "Train NMSE:  2.378349542617798\n",
      "Train NMSE:  2.1713950634002686\n",
      "Train NMSE:  1.9701581001281738\n",
      "Train NMSE:  1.934327244758606\n",
      "Train NMSE:  2.250455617904663\n",
      "Train NMSE:  1.6310455799102783\n",
      "Train NMSE:  1.650364875793457\n",
      "Train NMSE:  1.6383525133132935\n",
      "Train NMSE:  1.3603026866912842\n",
      "Train NMSE:  1.8533892631530762\n",
      "Train NMSE:  2.533019781112671\n",
      "Train NMSE:  1.9313828945159912\n",
      "Train NMSE:  2.6608691215515137\n",
      "Validating and Checkpointing!\n",
      "Best model Saved! Val NMSE:  65.54351842403412\n",
      "Epoch:  3 , Time Elapsed:  1.3590330878893535  mins\n",
      "Train NMSE:  1.8147132396697998\n",
      "Train NMSE:  2.594724178314209\n",
      "Train NMSE:  3.198305130004883\n",
      "Train NMSE:  2.326693296432495\n",
      "Train NMSE:  2.6544485092163086\n",
      "Train NMSE:  1.9895544052124023\n",
      "Train NMSE:  2.7656781673431396\n",
      "Train NMSE:  1.8719629049301147\n",
      "Train NMSE:  1.3024489879608154\n",
      "Train NMSE:  1.6035292148590088\n",
      "Train NMSE:  1.4716870784759521\n",
      "Train NMSE:  1.7021044492721558\n",
      "Train NMSE:  1.4993715286254883\n",
      "Train NMSE:  1.5157426595687866\n",
      "Train NMSE:  1.4140273332595825\n",
      "Train NMSE:  1.5034871101379395\n",
      "Train NMSE:  1.808803915977478\n",
      "Train NMSE:  1.3016992807388306\n",
      "Train NMSE:  1.2468857765197754\n",
      "Train NMSE:  1.9543671607971191\n",
      "Train NMSE:  1.3972222805023193\n",
      "Train NMSE:  3.474301338195801\n",
      "Train NMSE:  1.6409355401992798\n",
      "Train NMSE:  2.1158814430236816\n",
      "Train NMSE:  2.2551705837249756\n",
      "Train NMSE:  2.311779260635376\n",
      "Train NMSE:  1.6588551998138428\n",
      "Train NMSE:  1.768438458442688\n",
      "Train NMSE:  1.5172849893569946\n",
      "Train NMSE:  1.7875272035598755\n",
      "Train NMSE:  1.2304139137268066\n",
      "Train NMSE:  1.4304119348526\n",
      "Train NMSE:  1.0328575372695923\n",
      "Train NMSE:  1.4460158348083496\n",
      "Train NMSE:  1.577011227607727\n",
      "Train NMSE:  1.3939813375473022\n",
      "Train NMSE:  1.3368192911148071\n",
      "Train NMSE:  2.1397740840911865\n",
      "Train NMSE:  1.3927788734436035\n",
      "Train NMSE:  1.6500362157821655\n",
      "Train NMSE:  2.654916763305664\n",
      "Train NMSE:  1.1703369617462158\n",
      "Train NMSE:  1.7782328128814697\n",
      "Train NMSE:  1.4471830129623413\n",
      "Train NMSE:  1.0270034074783325\n",
      "Validating and Checkpointing!\n",
      "Best model Saved! Val NMSE:  46.886757016181946\n",
      "Epoch:  4 , Time Elapsed:  2.0493324557940165  mins\n",
      "Train NMSE:  1.3008605241775513\n",
      "Train NMSE:  1.3781828880310059\n",
      "Train NMSE:  1.4883395433425903\n",
      "Train NMSE:  1.8588145971298218\n",
      "Train NMSE:  1.489033579826355\n",
      "Train NMSE:  1.446445345878601\n",
      "Train NMSE:  1.3381285667419434\n",
      "Train NMSE:  1.4676586389541626\n",
      "Train NMSE:  1.2793207168579102\n",
      "Train NMSE:  1.423648715019226\n",
      "Train NMSE:  2.074450969696045\n",
      "Train NMSE:  1.5141297578811646\n",
      "Train NMSE:  1.2056893110275269\n",
      "Train NMSE:  1.3568174839019775\n",
      "Train NMSE:  1.3157950639724731\n",
      "Train NMSE:  1.0732048749923706\n",
      "Train NMSE:  1.3743934631347656\n",
      "Train NMSE:  1.1315057277679443\n",
      "Train NMSE:  4.3757405281066895\n",
      "Train NMSE:  1.0894811153411865\n",
      "Train NMSE:  1.9963167905807495\n",
      "Train NMSE:  1.531116008758545\n",
      "Train NMSE:  1.848534107208252\n",
      "Train NMSE:  1.7343531847000122\n",
      "Train NMSE:  1.5972658395767212\n",
      "Train NMSE:  1.4719635248184204\n",
      "Train NMSE:  1.412889003753662\n",
      "Train NMSE:  0.9961944818496704\n",
      "Train NMSE:  1.8254255056381226\n",
      "Train NMSE:  1.0567504167556763\n",
      "Train NMSE:  1.124474287033081\n",
      "Train NMSE:  1.1247957944869995\n",
      "Train NMSE:  1.557818055152893\n",
      "Train NMSE:  0.9944992661476135\n",
      "Train NMSE:  1.8032532930374146\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "device = torch.device('cuda')\n",
    "\n",
    "for input in inputs:\n",
    "    for output in outputs:\n",
    "        dataset.input = input\n",
    "        dataset.out = output\n",
    "        model = GreenhouseMidFusionRegressor(input_data_type = input, num_outputs = NumOutputs, conv_type = ConvType)\n",
    "        model.to(device)\n",
    "        params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "        optimizer = torch.optim.Adam(params, \n",
    "                                     lr=0.0005, \n",
    "                                     betas=(0.9, 0.999), \n",
    "                                     eps=1e-08, \n",
    "                                     weight_decay = 0, \n",
    "                                     amsgrad = False)  # select an optimzer for each run\n",
    "    \n",
    "                                \n",
    "        best_val_loss = 9999999 # initial dummy value\n",
    "        current_val_loss = 0\n",
    "        # training_val_loss=0\n",
    "           \n",
    "        writer = SummaryWriter()\n",
    "        start = time.time()\n",
    "                                \n",
    "        for epoch in range(num_epochs):\n",
    "            with open('run.txt', 'a') as f:\n",
    "                f.write('\\n')\n",
    "                f.write('Epoch: '+ str(epoch + 1) + ', Time Elapsed: '+ str((time.time()-start)/60) + ' mins')\n",
    "            print('Epoch: ', str(epoch + 1), ', Time Elapsed: ', str((time.time()-start)/60), ' mins')\n",
    "\n",
    "            train_single_epoch(model, dataset, device, criterion, optimizer, writer, epoch, train_loader)\n",
    "\n",
    "            best_val_loss = validate(model, dataset, device, training_category, sav_dir, criterion, writer, epoch, val_loader, best_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the PyTorch datalaoder the autonomous greenhouse dataset.\n",
    "testset = GreenhouseDataset(rgb_dir = RGB_Data_Dir, \n",
    "                            d_dir = Depth_Data_Dir, \n",
    "                            jsonfile_dir = JSON_Files_Dir, \n",
    "                            transforms = get_transforms(train=False, means=dataset.means, stds=dataset.stds))\n",
    "\n",
    "# Grab last 50 images as test dataset\n",
    "testset.df = testset.df[-50:]\n",
    "\n",
    "# Get testset_size\n",
    "testset_size = testset.df.shape[0]\n",
    "\n",
    "# Create test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(testset, \n",
    "                                          batch_size = 50,\n",
    "                                          num_workers = 0, \n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss functions for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cri = NMSELoss()\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is  RGB-D\n",
      "FW MSE:  16857.876953125\n",
      "DW MSE:  4.854626655578613\n",
      "H MSE:  3.97654390335083\n",
      "D MSE:  22.738414764404297\n",
      "LA MSE:  5795591.0\n",
      "Overall NMSE:  1.632205843925476\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "device=torch.device('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input in inputs:\n",
    "        final = torch.zeros((testset_size,0))\n",
    "        all_targets = torch.zeros((testset_size,0))\n",
    "        for output in outputs:\n",
    "            print('Input is ', input)\n",
    "            testset.input = input\n",
    "            testset.out = output\n",
    "\n",
    "            device=torch.device('cuda')\n",
    "            model= GreenhouseMidFusionRegressor(input_data_type = input, \n",
    "                                                num_outputs = NumOutputs, \n",
    "                                                conv_type = ConvType)\n",
    "            model.to(device)\n",
    "            model.load_state_dict(torch.load(sav_dir + 'bestmodel' + training_category + '_' + input + '_' + output + '.pth'))\n",
    "            model.eval()\n",
    "\n",
    "\n",
    "            if output=='All':\n",
    "                ap=torch.zeros((0,5))\n",
    "                at=torch.zeros((0,5))\n",
    "            else:\n",
    "                ap=torch.zeros((0,1))\n",
    "                at=torch.zeros((0,1))\n",
    "\n",
    "            for rgbd, targets in test_loader:\n",
    "                rgbd = rgbd.to(device)\n",
    "                targets = targets.to(device)\n",
    "                preds = model(rgbd)\n",
    "                # mse_loss=mse(preds, targets)\n",
    "                # nmse=criterion(preds, targets)\n",
    "                # nmse, pred=cri(preds, targets)\n",
    "                ap=torch.cat((ap, preds.detach().cpu()), 0)\n",
    "                at=torch.cat((at, targets.detach().cpu()), 0)\n",
    "\n",
    "            if output=='All':\n",
    "                print('FW MSE: ', str(mse(ap[:,0],at[:,0]).tolist()))\n",
    "                print('DW MSE: ', str(mse(ap[:,1],at[:,1]).tolist()))\n",
    "                print('H MSE: ', str(mse(ap[:,2],at[:,2]).tolist()))\n",
    "                print('D MSE: ', str(mse(ap[:,3],at[:,3]).tolist()))\n",
    "                print('LA MSE: ', str(mse(ap[:,4],at[:,4]).tolist()))\n",
    "            else:\n",
    "                final=torch.cat((final, ap.detach().cpu()),1)\n",
    "                all_targets=torch.cat((all_targets, at.detach().cpu()),1)\n",
    "                print(output,' MSE: ', str(mse(ap,at).tolist()))\n",
    "\n",
    "        if output == 'All':\n",
    "            print('Overall NMSE: ', str(cri(ap,at).tolist()))\n",
    "        else:\n",
    "            print('Overall NMSE: ', str(cri(final,all_targets).tolist()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52f36c1f6eb8678621dd418d5b8ad0837811436cfff124e7936f8a687fb60368"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('greenhouse': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
